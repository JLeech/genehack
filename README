README

структура проекта следующая:

/eveleech
-сам референсный геном, разделённый на хромосомы (1..23).txt
-оригинал референсного генома hg19.fa
-headers.py - распечатывает названия всех последовательностей из hg19.fa в исходном порядке.
-spliter.py - разбивает исходный геном hg19.fa на файлы, содержащие только одну хромосому. Имена созданных файлов - это номер
 	последовательности в hg19.fa, начиная с 0. Структура файлов: первая строка содержит смещение последовательности в референсном
 	геноме, вторая строка - сама последовательность.Используя эти 2 скрипта мы получаем массив файлов с хромосомами из исходного 
 	референсного генома, каждый из которых занимает менее 250МБ данных.

/eveleech/genomes
-выделенная информация из других геномов. То есть позиция и значение разницы относительно референсного + столбец alt, ради интереса

/eveleech/genomes/progs
- Counter.java - программа для составления словаря разниц, его сортировки по позициям. Принимает несколько аргументов:
	java Counter "/eveleech/genomes" true 40
	- первый аргумент - путь к геномам. Начинает парсить всё, что начинается с "vcf"
	- второй вргумент - в выводе печатать нормированные частоты или количество разниц относительно референсного. (true если частоты)
	- третий аргумент - сколько геномов считать (по-умолчанию 20)
	на выходе выдаёт отсортированный по позициям файл vcf. (collected_sorted.vcf)

- mapper.rb - программа для создания базок elasticsearch. Так мы сначала хотели всё через него делать, то там для всех баз.
- loader.rb - программа для загрузки данных в сам elastic. Не очень оптимально написано, так как на каждую запись генерируется вызов
 	API. По уму, нужно, например, по 1000 запросов завернуть в butch, и одной транзакцией залить, но к тому времени мы уже отказались 
 	от elastic и код не препиливали; elastic остался на сервере.
- hystograms.py - содержит набор методов для визуализации данных из VCF файла. (их надо переписать!)
- некоторые питоновские файлы - скрипты, которые как proof of concept использовались. Сейчас они переписаны и внутри Counter.java.

/eveleech/genomes/progs/pics 
-примеры картинок с частотами.

~/genomes/progs

P.S. 
Как нам показалось, сбор статистики очень хорошо ложиться на map/reduce подход, в частности Hadoop. В последний день мы подняли standalone 
ноду на ноутбуке, написали map/reduce, запустили одну последовательность, но ноут не очень хорош для этого, так что дальше прототипа не пошло. 
Исходники есть, основаны на примере WordCounter для Hadoop. Интересно, что hadoop можно запустить поверх elastic, и тогда визуализация может 
быть очень быстрой и с последними данными, изменёнными hadoop'ом.
